{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " #importing the library\n",
    "from google_images_download import google_images_download  \n",
    "import flickrapi\n",
    "import urllib\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def downloadGoogle(keywords):\n",
    "    response = google_images_download.googleimagesdownload()   #class instantiation\n",
    "\n",
    "    arguments = {\"keywords\":keywords,\"limit\":100,\"print_urls\":True}   #creating list of arguments\n",
    "    paths = response.download(arguments)   #passing the arguments to the function\n",
    "    print(paths)   #printing absolute paths of the downloaded images\n",
    "    \n",
    "def downloadPhoto(keyword):\n",
    "    count = 1\n",
    "    # Flickr api access key \n",
    "    flickr=flickrapi.FlickrAPI('3cad3423b15a31821bc2ffc770a61639', '0540fac97f445279', cache=True)\n",
    "\n",
    "    photos = flickr.walk(text=keyword,\n",
    "                     tag_mode='all',\n",
    "                     tags=keyword,\n",
    "                     extras='url_c',\n",
    "                     per_page=100,           # may be you can try different numbers..\n",
    "                     sort='relevance')\n",
    "\n",
    "    urls = []\n",
    "    for i, photo in enumerate(photos):\n",
    "        print (i)\n",
    "    \n",
    "        url = photo.get('url_c')\n",
    "        urls.append(url)\n",
    "    \n",
    "        # get 50 urls\n",
    "        if i > 50:\n",
    "            break\n",
    "\n",
    "\n",
    "    path = 'C:\\\\Users\\\\Tai\\\\Notebooks\\\\Project\\\\downloads\\\\'+keyword+\"\\\\\"\n",
    "\n",
    "#Download image from the url and save it to '00001.jpg'\n",
    "    for i in range (0, len(urls)):\n",
    "        try:\n",
    "            file_path = os.path.join(path, '0000'+str(count)+'.jpg')\n",
    "            urllib.request.urlretrieve(urls[i], file_path)\n",
    "            count+=1\n",
    "        except Exception as e:\n",
    "             print('failed to download image')\n",
    "\n",
    "    \n",
    "#Resize the image and overwrite it\n",
    "    for i in range(1, count):\n",
    "        file_path = os.path.join(path, '0000'+str(i)+'.jpg')\n",
    "        image = Image.open(file_path) \n",
    "        image = image.resize((256, 256), Image.ANTIALIAS)\n",
    "        image.save(file_path)   \n",
    "        \n",
    "df = pd.read_excel(\"PlantList.xlsx\")\n",
    "df[\"Scientific Name\"].dropna()\n",
    "#download using GoogleAPI \n",
    "#Make sure to use GoogleAPI first as it will create folders for each classes\n",
    "for name in df[\"Scientific Name\"].dropna():\n",
    "    downloadGoogle(name)\n",
    "    \n",
    "# download using FlickrAPI   \n",
    "for name in df[\"Scientific Name\"].dropna():\n",
    "    downloadPhoto(keyword.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
